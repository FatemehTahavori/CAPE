{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyO4rJeY54l70zPQ1YQlQSnl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FatemehTahavori/CAPE/blob/master/calibration_isotonic_regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "id": "PMfM2szUMTUw",
        "outputId": "25600731-a1b4-4c11-f6ba-ef818e5f0235"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1d6CChySejVXeGpF2B335tmb_W23Xkt38\n",
            "To: /content/predictions_random_forest_Adult_dataset.csv\n",
            "100%|██████████| 110k/110k [00:00<00:00, 47.6MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AUC - before/after:         0.8781398450768403 / 0.8777692307692309\n",
            "Accuracy - before/after:    0.8477886977886978 / 0.845945945945946\n",
            "Log loss - before/after:    0.6305257728714894 / 0.35572214331077795\n",
            "Brier score - before/after: 0.11168379606879607 / 0.11009118568385362\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:44: DeprecationWarning: scipy.maximum is deprecated and will be removed in SciPy 2.0.0, use numpy.maximum instead\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:45: DeprecationWarning: scipy.minimum is deprecated and will be removed in SciPy 2.0.0, use numpy.minimum instead\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:46: DeprecationWarning: scipy.log is deprecated and will be removed in SciPy 2.0.0, use numpy.lib.scimath.log instead\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:46: DeprecationWarning: scipy.subtract is deprecated and will be removed in SciPy 2.0.0, use numpy.subtract instead\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nAUC - before/after:         0.8781398450768403 / 0.8777692307692309\\nAccuracy - before/after:    0.8477886977886978 / 0.845945945945946\\nLog loss - before/after:    0.6305257728714894 / 0.35572214331077795\\nBrier score - before/after: 0.11168379606879607 / 0.11009118568385362\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "import numpy as np\n",
        "import scipy as sp\n",
        "import pandas as pd\n",
        "from pathlib import Path \n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import brier_score_loss\n",
        "from sklearn.metrics import roc_auc_score as AUC\n",
        "from sklearn.isotonic import IsotonicRegression as IR\n",
        "\n",
        "# load data, predictions from a random forest\n",
        "import gdown\n",
        "id = \"1d6CChySejVXeGpF2B335tmb_W23Xkt38\"\n",
        "gdown.download(id=id, quiet=False)\n",
        "input_file = '/content/predictions_random_forest_Adult_dataset.csv'\n",
        "\n",
        "y_and_p = np.loadtxt(input_file, delimiter = ',')\n",
        "\n",
        "y = y_and_p[:,0]\n",
        "p = y_and_p[:,1]\n",
        "\n",
        "# y is the label, we convert it to 0 if it was -1\n",
        "y[y == -1] = 0\n",
        "\n",
        "# Split data in half for train and test\n",
        "train_indx_end = int(y.shape[0] / 2)\n",
        "test_index_start = train_indx_end + 1\n",
        "\n",
        "y_train = y[0:train_indx_end]\n",
        "y_test =y[test_index_start:]\n",
        "p_train = p[0:train_indx_end]\n",
        "p_test =p[test_index_start:]\n",
        "\n",
        "# IsotonicRegression\n",
        "ir = IR(out_of_bounds = 'clip')\n",
        "ir.fit(p_train, y_train)\n",
        "p_calibrated = ir.transform(p_test)\n",
        "# if p_calibrated is nan we convert it to 0\n",
        "p_calibrated[np.isnan(p_calibrated)] = 0\n",
        "\n",
        "# This calculates log_loss\n",
        "def log_loss(actual, prediction):\n",
        "\tepsilon = 1e-15\n",
        "\tprediction = sp.maximum(epsilon, prediction)\n",
        "\tprediction = sp.minimum(1-epsilon, prediction)\n",
        "\tlog_loss = sum(actual*sp.log(prediction) + sp.subtract(1,actual)*sp.log(sp.subtract(1,prediction)))\n",
        "\tlog_loss = log_loss * -1.0/len(actual)\n",
        "\treturn log_loss\n",
        "\n",
        "auc = AUC(y_test, p_test)\n",
        "auc_calibrated = AUC(y_test,p_calibrated)\n",
        "accuracy = accuracy_score(y_test, np.round(p_test))\n",
        "accuracy_calibrated = accuracy_score(y_test, np.round(p_calibrated))\n",
        "log_loss_score = log_loss(y_test, p_test)\n",
        "log_loss_calibrated = log_loss(y_test, p_calibrated)\n",
        "brier_score = brier_score_loss(y_test, p_test)\n",
        "brier_score_calibrated = brier_score_loss(y_test, p_calibrated)\n",
        "\n",
        "print(\"AUC - before/after:        \", auc, \"/\", auc_calibrated)\n",
        "print(\"Accuracy - before/after:   \", accuracy, \"/\", accuracy_calibrated)\n",
        "print(\"Log loss - before/after:   \", log_loss_score, \"/\", log_loss_calibrated)\n",
        "print(\"Brier score - before/after:\", brier_score, \"/\", brier_score_calibrated)\n",
        "\n",
        "\n",
        "df = pd.DataFrame({'p_train': p_train, 'y_train': y_train, 'p_test': p_test, 'y_test': y_test})\n",
        "filepath = Path('output/ir_python.csv')  \n",
        "filepath.parent.mkdir(parents=True, exist_ok=True)  \n",
        "df.to_csv(filepath, index=False)  \n",
        "\n",
        "\"\"\"\n",
        "AUC - before/after:         0.8781398450768403 / 0.8777692307692309\n",
        "Accuracy - before/after:    0.8477886977886978 / 0.845945945945946\n",
        "Log loss - before/after:    0.6305257728714894 / 0.35572214331077795\n",
        "Brier score - before/after: 0.11168379606879607 / 0.11009118568385362\n",
        "\"\"\""
      ]
    }
  ]
}